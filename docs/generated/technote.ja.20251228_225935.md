+++
title = "Technical Note: The Physics of Conchordal"
date = 2025-12-25
description = "Conchordalエコシステムを支える心理音響アルゴリズム、対数信号処理、人工生命戦略の詳細"
template = "page.html"
[extra]
source_commit = "9a8d3ea"
author = "Koichi Takahashi"
last_updated = "2025-12-28"
source_version = "0.1.0"
source_snapshot = "2025-12-26T21:46:36+09:00"
generated_by = "sonnet"
+++

# 1. はじめに:生体音響パラダイム

Conchordalは、ジェネラティブ音楽と計算オーディオの既成概念からの根本的な逸脱を表している。従来のシステムが記号的操作—量子化されたピッチ(MIDI、平均律)と離散化された時間(BPM、小節)のグリッド上で動作する—に依存しているのに対し、Conchordalは聴覚知覚の連続的で生物学的に根拠のあるシミュレーションとして機能する。音楽構造は抽象的な作曲の産物ではなく、音響的サバイバルの創発的特性であるという立場をとる。

本技術ノートは、システムのアーキテクチャ、信号処理アルゴリズム、人工生命戦略の網羅的リファレンスとして機能する。Conchordalが心理音響学の原理—特に臨界帯域理論、仮想ピッチ知覚、神経エントレインメント—を自律的エコシステムのダイナミクスとどのように統合しているかを詳述する。この環境において、音は生きた有機体として扱われ、代謝、感覚処理能力、敵対的スペクトル地形をナビゲートする自律性を持つ「Individual」として存在する。

システムの創発的振る舞いは、統一された適応度関数、すなわち協和の追求によって駆動される。Conchordalエコシステム内のエージェントは、事前に書かれたスコアに従わない。代わりに、彼らは環境を継続的に分析し、「スペクトル快適性」—感覚的粗さの最小化として定義される—と「和声的安定性」、すなわち仮想基音強度の最大化を追求する。その結果は、決定論的シーケンシングではなく、物理法則の相互作用を通じて和声、リズム、音色が有機的に進化する自己組織化サウンドスケープである。

本文書は、Conchordalアーキテクチャの3つの基礎的柱を探求する:

1.  **心理音響座標系**: リニアヘルツと整数MIDIノートを置き換える`Log2Space`とERBスケールの数学的枠組み。
2.  **認知ランドスケープ**: 生音声ストリームから粗さ($R$)と和声性($H$)フィールドを計算するリアルタイムDSPパイプライン。
3.  **生命エンジン**: 音声エンティティの代謝、移動、神経エントレインメントを統治するエージェントベースモデル。

# 2. 心理音響座標系

Conchordalの重要な革新は、内部処理のための線形周波数スケール($f$)の拒否である。人間の聴覚知覚は本質的に対数的である。ピッチ間隔の知覚は周波数差ではなく周波数比に基づいている。これを正確かつ効率的にモデル化するため、Conchordalは蝸牛のトノトピックマップに計算グリッドを整列させるカスタム座標系`Log2Space`を確立する。

## 2.1 Log2空間の基礎

`Log2Space`構造体は、システム内のすべてのスペクトル分析、カーネル畳み込み、エージェント配置のバックボーンとして機能する。物理的周波数領域($f$ Hz単位)を知覚的対数領域($l$)にマッピングする。

### 2.1.1 数学的定義

ヘルツから内部対数座標への変換は、周波数の2を底とする対数として定義される。この選択は意図的である:2を底とする場合、1.0の増分はピッチ知覚における最も基本的な間隔であるオクターブに正確に対応する。

$$ l(f) = \log_2(f) $$

オーディオスレッドの合成パラメータを導出するために使用される逆変換は:

$$ f(l) = 2^l $$

座標空間は解像度パラメータ`bins_per_oct`($B$)によって定義されるグリッドに離散化される。このパラメータがシミュレーションの粒度を決定する。典型的な値$B=48$または$B=96$は、連続的なピッチグライドとミクロトーナルインフレクションに十分な半音以下の解像度を提供する。ステップサイズ$\Delta l$は、スペクトル範囲全体で一定である:

$$ \Delta l = \frac{1}{B} $$

### 2.1.2 グリッド構築とインデックス付け

`Log2Space`構造体は、設定範囲$[f_{min}, f_{max}]$にまたがるすべてのビンの中心周波数を事前計算する。ビン数$N$は完全なカバレッジを保証するように決定される:

$$ N = \lfloor \frac{\log_2(f_{max}) - \log_2(f_{min})}{\Delta l} \rfloor + 1 $$

システムは、DSP操作中の$O(1)$アクセスのために2つの並列ベクトルを維持する:

*   `centers_log2`: 対数座標 $l_i = \log_2(f_{min}) + i \cdot \Delta l$。
*   `centers_hz`: 事前計算された線形周波数 $f_i = 2^{l_i}$。

この事前計算はリアルタイムパフォーマンスに不可欠であり、スペクトルカーネルの内部ループ内での高コストな`log2`および`pow`呼び出しの必要性を除去する。メソッド`index_of_freq(hz)`は量子化ロジックを提供し、任意の浮動小数点周波数を最も近いビンインデックスにマッピングする。

## 2.2 定Q帯域幅特性

`Log2Space`は本質的にスペクトル全体で定Q(定品質係数)特性を強制する。信号処理用語では、$Q$は中心周波数と帯域幅の比として定義される: $Q = f / \Delta f$。

線形システム(標準FFTなど)では、$\Delta f$が定数であるため、$Q$は周波数とともに増加する。`Log2Space`では、$i$番目のビンの帯域幅$\Delta f_i$が中心周波数$f_i$に比例してスケールする。この特性は人間の聴覚システムの周波数選択性を模倣しており、耳の周波数を解決する能力は周波数が増加するにつれて(絶対Hz単位で)減少する。この整列により、Conchordalは計算リソースを効率的に配分できる—高周波数では高時間分解能を、低周波数では高スペクトル分解能を使用—手動マルチレート処理なしで。

## 2.3 等価矩形帯域幅(ERB)スケール

`Log2Space`がピッチ関係(オクターブ、倍音)を処理する一方で、耳の臨界帯域を完全にはモデル化しない。臨界帯域は純粋な対数マッピングが示唆するよりも低周波数で広い。感覚的粗さ(不協和)を正確に計算するため、ConchordalはGlasberg & Moore(1990)モデルに基づく等価矩形帯域幅(ERB)スケールを実装する。

`core/erb.rs`モジュールは、粗さカーネルによって使用される変換関数を提供する。周波数$f$(Hz)からERBレート単位$E$への変換は:

$$ E(f) = 21.4 \log_{10}(0.00437f + 1) $$

周波数$f$における臨界帯域の帯域幅は:

$$ BW_{ERB}(f) = 24.7(0.00437f + 1) $$

このスケールは`Log2Space`とは異なる。`Log2Space`がピッチと和声性のためのドメイン(関係がオクターブ不変)である一方、粗さ計算は干渉を評価するためにスペクトルエネルギーをERBドメインにマッピングする必要がある。システムは事実上スペクトルのデュアルビューを維持する:倍音テンプレート用の厳密に対数的なものと、不協和評価用の心理音響的なもの。

# 3. 聴覚ランドスケープ:環境の分析

「ランドスケープ」はConchordalの中心的データ構造である。すべてのエージェントの共有環境として機能し、各周波数ビンの心理音響的「ポテンシャル」を表す動的スカラーフィールドである。エージェントは互いに直接相互作用しない。彼らはランドスケープと相互作用し、ランドスケープが全体の集団のスペクトルエネルギーを集約する。これにより、シミュレーションの複雑さがエージェント数から分離される($O(N)$ vs $O(N^2)$)。

ランドスケープは分析ワーカーによって各オーディオフレーム(またはブロック)で更新される。3つの主要なメトリクスを統合する:

*   **粗さ($R$)**: 近接部分音間の急速なビートによって引き起こされる感覚的不協和。
*   **和声性($H$)**: 仮想ピッチ強度とスペクトル周期性の尺度。
*   **慣れ($\Psi$)**: 聴覚疲労を表す負のフィードバックループ。

周波数$f$、時刻$t$における正味の協和($C$)は、エージェントがサンプリングする適応度フィールドである:

$$ C(f,t) = H(f,t) - k_r \cdot R(f,t) - w_h \cdot \Psi(f,t) $$

## 3.1 非定常ガボール変換(NSGT)

`Log2Space`にスペクトルデータを入力するため、Conchordalは非定常ガボール変換(NSGT)のカスタム実装を使用する。固定ウィンドウサイズを使用する短時間フーリエ変換(STFT)とは異なり、NSGTはセクション2.2で導出された定Q特性を維持するため、ウィンドウ長$L$を周波数に反比例して変化させる。

### 3.1.1 カーネルベーススペクトル分析

`core/nsgt_kernel.rs`の実装は、この変換を効率的に実行するためにスパースカーネルアプローチを利用する。各対数周波数帯域$k$に対して、時間領域カーネル$h_k$が事前計算される。このカーネルは、帯域の中心周波数$f_k$における複素正弦波と、長さ$L_k \approx Q \cdot f_s / f_k$の周期的ハンウィンドウ$w_k$を結合する。

$$ h_k[n] = w_k[n] \cdot e^{-j 2\pi f_k n / f_s} $$

これらのカーネルは初期化中に周波数領域($K_k[\nu]$)に変換される。パフォーマンスを最適化するため、システムはこれらの周波数カーネルをスパース化し、有意なエネルギーを持つビンのみを保存する。

実行時、システムは入力オーディオバッファに対して単一のFFTを実行してスペクトル$X[\nu]$を取得する。帯域$k$の複素係数$C_k$は、周波数領域における内積を介して計算される:

$$ C_k = \frac{1}{N_{fft}} \sum_{\nu} X[\nu] \cdot K_k^*[\nu] $$

この「1回のFFT、多数のカーネル」アプローチにより、Conchordalは各帯域に対して個別のDFTを計算したり、再帰フィルターバンクを使用したりする計算オーバーヘッドなしに、20Hzから20kHzをカバーする高解像度の対数間隔スペクトルを生成できる。

### 3.1.2 リアルタイム時間スムージング

生のスペクトル係数$C_k$は、オーディオ入力の確率的性質(特にノイズベースのエージェント)により高い分散を示す。エージェントがサンプリングできる安定したフィールドを作成するため、`RtNsgtKernelLog2`構造体はNSGTを時間スムージング層でラップする。

帯域ごとのリーキー積分器(指数スムージング)を実装する。重要なのは、時定数$\tau$が周波数依存であることである。ゆっくり進化する低周波数はより長い$\tau$でスムージングされ、過渡的詳細を持つ高周波数はより短い$\tau$を持つ。

$$ y_k[t] = (1 - \alpha_k) \cdot |C_k[t]| + \alpha_k \cdot y_k[t-1] $$

ここで、スムージング係数$\alpha_k$はフレーム間隔$\Delta t$から導出される:

$$ \alpha_k = e^{-\Delta t / \tau(f_k)} $$

これは耳の「積分時間」をモデル化し、ランドスケープが瞬間的信号パワーではなく心理音響的知覚を反映することを保証する。

## 3.2 粗さ($R$)計算:Plomp-Leveltモデル

粗さは、同じ臨界帯域内に収まるが単一音として知覚されるほど十分に近接していないスペクトル成分の干渉によって引き起こされる「荒々しさ」または「ブーン」という感覚である(ビート)。ConchordalはERBドメインでの畳み込みを介してPlomp-Leveltモデルのバリエーションを実装する。

### 3.2.1 干渉カーネル

計算の核心は、`core/roughness_kernel.rs`で定義される粗さカーネルである。このカーネル$K_{rough}(\Delta z)$は、$\Delta z$ ERBで分離された2つの部分音間の干渉曲線をモデル化する。曲線は部分音が分離するにつれて急速に上昇するペナルティを作成し、約0.25 ERB(最大粗さ)でピークに達し、その後さらに分離するにつれて減衰する。

実装は、この形状を生成するためにパラメータ化された関数`eval_kernel_delta_erb`を使用する:

$$ g(\Delta z) = e^{-\frac{\Delta z^2}{2\sigma^2}} \cdot (1 - e^{-(\frac{\Delta z}{\sigma_{suppress}})^p}) $$

第2項は抑制係数であり、$\Delta z \to 0$としてカーネルがゼロになることを保証し、単一の純音が自己粗さを生成するのを防ぐ。

### 3.2.2 畳み込みアプローチ

すべてのスペクトルビンのペアワイズ粗さ計算($N^2$複雑度)は、リアルタイムアプリケーションには計算的に禁止的である。Conchordalは粗さ計算を線形畳み込みとして扱うことでこれを解決する。

1.  **マッピング**: NSGTからの対数間隔振幅スペクトルは、線形ERBグリッドにマッピング(または補間)される。
2.  **畳み込み**: この密度$A(z)$は、事前計算された粗さカーネル$K_{rough}$と畳み込まれる。

$$ R(z) = (A * K_{rough})(z) = \int A(z-\tau) K_{rough}(\tau) d\tau $$

結果$R(z)$は周波数$z$における「粗さポテンシャル」を表す。エージェントが$z$に音を配置した場合、既存のスペクトルエネルギーと相互作用して$R(z)$に比例する粗さを生成する。協和を求めるエージェントはこのフィールドのピークを積極的に回避する。

## 3.3 和声性($H$):兄弟投影アルゴリズム

粗さがエージェントを不協和から遠ざける(分離)一方、和声性($H$)は融合—一貫したコードと音色の創造—に向けて駆動する。Conchordalは「兄弟投影」と呼ばれる新しいアルゴリズムを導入してこのフィールドを計算する。このアルゴリズムは、周波数領域で完全に脳の「共通基音」検出(仮想ピッチ)メカニズムを近似する。

### 3.3.1 概念:仮想基音

アルゴリズムは、周波数$f$におけるスペクトルピークがその下位倍音($f/2, f/3, f/4 \dots$)における基本周波数(基音)の潜在的存在を示唆するとする。複数のスペクトルピークが共通の下位倍音を共有する場合、その下位倍音は強い「仮想基音」を表す。

### 3.3.2 2パス投影

アルゴリズムは対数グリッドの整数特性を利用して、`Log2Space`スペクトル上で2パスで動作する:

1.  **下方投影(基音探索)**: 現在のスペクトルエンベロープが「下方にスミア」される。エネルギーを持つすべてのビン$i$に対して、アルゴリズムは整数$k \in \{1, 2, \dots, N\}$に対してビン$i - \log_2(k)$にエネルギーを追加する。
    
    $$ Roots[i] = \sum_k A[i + \log_2(k)] \cdot w_k $$

    ここで、$w_k$は倍音インデックス$k$とともに減衰する重み係数(例: $k^{-\rho}$)であり、低次倍音が高次倍音よりも強く基音を示唆することを反映する。結果`Roots`は各周波数における仮想ピッチの強度を記述する。

2.  **上方投影(倍音共鳴)**: システムは次に`Roots`スペクトルを上方に投影する。強い基音が$f_r$に存在する場合、そのすべての自然倍音($f_r, 2f_r, 3f_r \dots$)に対する安定性を示唆する。
    
    $$ H[i] = \sum_m Roots[i - \log_2(m)] \cdot w_m $$

**創発的調性安定性**: 200 Hzの単一音を持つ環境を考える。

*   **ステップ1(下方)**: 100 Hz($f/2$)、66.6 Hz($f/3$)、50 Hz($f/4$)などに基音を投影する。
*   **ステップ2(上方)**: 100 Hz基音は100、200、300、400、500... Hzに安定性を投影する。
    *   300 Hzは100 Hz基音の完全5度である。
    *   500 Hzは100 Hz基音の長3度である。

したがって、西洋音楽理論のハードコードされた知識なしに、システムは長3度と完全5度の関係における安定性ピークを自然に生成する。これは単に倍音列の物理学の帰結である。200 Hzのエージェントは300 Hzと500 Hzに「重力井戸」を作成し、他のエージェントを招いてメジャー三和音を形成する。

### 3.3.3 鏡像二元性:上音列対下音列

`core/harmonicity_kernel.rs`の実装には重要なパラメータ`mirror_weight`($\alpha$)が含まれる。このパラメータは2つの異なる投影パスをブレンドする:

*   **パスA(上音列/メジャー)**: 上記の標準的な「下方-上方」投影。上音列に基づく重力を作成し、メジャー調性を優遇する。
*   **パスB(下音列/マイナー)**: 反転した「上方-下方」投影。共通の上音を見つけて下音を投影する。これはパスAの理論的双対であり、マイナーまたはフリジアン調性(下音列)を優遇する。

$$ H_{final} = (1-\alpha)H_{overtone} + \alpha H_{undertone} $$

`mirror_weight`を変調することで、ユーザーは宇宙の基本物理学をメジャー中心からマイナー中心へと連続的に変態させ、エコシステムがそれに応じてどのように再編成されるかを観察できる。

## 3.4 慣れ:退屈メカニズム

システムが単一の最適コード(例:完全ユニゾンまたはオクターブ)を見つけてそこに永遠に留まるのを防ぐため、Conchordalは慣れ(聴覚疲労)の生理学的モデルを実装する。

慣れフィールドはスペクトルエネルギーの履歴を追跡する。これは本質的に振幅スペクトルの非常に遅いリーキー積分器である(時定数$\tau_{hab}$は通常5-10秒)。

$$ \Psi[t] = (1-\beta) \cdot A[t] + \beta \cdot \Psi[t-1] $$

このフィールド$\Psi$は最終的な協和$C$から減算される。エージェントが周波数$f$に長く留まりすぎると、$\Psi(f)$が増加し、$C(f)$が減少し、かつて快適だった場所が「退屈」(低適応度)になる。これによりエージェントは新しい新鮮な周波数へ移動することを強いられ、音楽の永続的進化を駆動する。

# 4. 生命エンジン:エージェントと自律性

「生命エンジン」は、DSPランドスケープ上で実行されるエージェントベースのシミュレーション層である。「Individuals」の集団を管理し、ライフサイクル、感覚処理、アクチュエーション(音声合成)を処理する。

## 4.1 Individual アーキテクチャ

`Individual`構造体(`life/individual.rs`)はエコシステムの原子単位である。生物学的「脳」と物理的「身体」を分離する2つの異なるモジュールで構成される。

### 4.1.1 SoundBody(アクチュエータ)

`SoundBody`トレイトはエージェントの音生成機能を定義する。波形のレンダリングとシステムへのスペクトルフットプリントの投影(ランドスケープ更新用)を担当する。

*   `SineBody`: 純粋な正弦波音を合成する。
*   `HarmonicBody`: 基音と一連の部分音からなる複雑な音を合成する。このボディは`TimbreGenotype`の概念を導入し、以下のようなパラメータをエンコードする:
    *   `stiffness`: 非調和係数(部分音列の伸張)。
    *   `brightness`: スペクトル傾斜(高次部分音の減衰)。
    *   `damping`: 周波数依存減衰率。
    *   `mode`: 調和的(整数倍)対金属的(非整数比)。

`HarmonicBody`は音色の進化を可能にする。高い剛性を持つエージェントは純粋に調和的なランドスケープでサバイバルが困難かもしれず、その非調和部分音が集団と衝突しないユニークな「スペクトルニッチ」を探すことを強いられる。

### 4.1.2 NeuralCore(コントローラ)

`NeuralCore`トレイトはエージェントの行動と内部状態を定義する。感覚入力($C, R, \Psi$)を処理し、エージェントの出力状態(`ArticulationSignal`)を決定する。

*   `KuramotoCore`: 最も高度な脳タイプで、位相同期のための蔵本モデルを実装する。エージェントの内部クロックをグローバル`NeuralRhythms`に結合する(セクション5参照)。
*   `DroneCore`: アンビエントテクスチャ用の簡略化された脳で、遅いドリフトと長いサステインに焦点を当てる。
*   `SequencedCore`: 事前プログラムされたエンベロープに従う決定論的脳で、「機械」要素やリズミックシードに有用。

## 4.2 ライフサイクルと代謝

Conchordalのエージェントは生物学的代謝をモデルとしたエネルギーダイナミクスによって統治される。`LifecycleConfig`は2つの存在モードを定義する:

*   **減衰**: エージェントは固定`initial_energy`プールで誕生する。時間とともにこのエネルギーを消費し(半減期)、ゼロに達すると死ぬ。これはプラックやパーカッションのような一過性の音をモデル化する。
*   **持続**: エージェントは`metabolism_rate`(毎秒のエネルギー損失)を持つが、`breath_gain`を介してエネルギーを得ることができる。
    *   **呼吸獲得**: これが重要なフィードバックループである。エージェントがエネルギーを回復する率は、その現在の協和の関数である。
    *   **サバイバル**: 不協和(低$C$)領域のエージェントは「飢える」—エネルギーが枯渇し、振幅が消え、最終的に死ぬ。協和(高$C$)領域のエージェントは「餌を得る」—エネルギーを維持または獲得し、より大きく長く歌うことができる。

このメカニクスはダーウィン的圧力を生み出す:**協和の生存**。音楽構造が創発するのは、和声関係を見つけるエージェントのみが生き残り聞かれるからである。

## 4.3 有機的移動ロジック

エージェントは静的ではない。適応度を改善するため周波数空間を移動する。`update_organic_movement`メソッドは生物学的制約を持つ離散候補選択を実装する。

1.  **感覚ポーリング**: エージェントは現在の周波数$f$と近くの少数の候補ピッチでランドスケープをサンプリングする。
2.  **候補比較**: 調整されたスコア(協和からペナルティを引いたもの)を比較し、利用可能な場合より良いターゲットを選択する。
3.  **コミットメント対ドリフト**:
    *   `commitment`パラメータがエージェントの「頑固さ」を決定する。高いコミットメントはエージェントを移動に抵抗させ、実質的に和声を固定する。低いコミットメントはエージェントを流動的にし、新しいコードへより容易にホップする。
    *   `PinkNoise`ジェネレータが揺れ(ランダムドリフト)を追加する。この確率性はシステムが局所最適(静的コード)に陥るのを防ぎ、動きに有機的で生きた質を与える。

移動は`Log2Space`のホップポリシーを使用する:`breath_gain`を介してフェードアウトし、ピッチを新しいターゲットにスナップし、フェードインする。これは連続的なポルタメントではなく離散的なジャンプを生成する。

# 5. 時間ダイナミクス:神経リズム

Conchordalはマスタークロックやメトロノームの概念を避ける。代わりに、時間は神経振動(脳波)に触発された連続的変調フィールドによって構造化される。これは「空間」ランドスケープの「時間」相当である。

## 5.1 変調バンク

`NeuralRhythms`構造体は生理学的周波数帯域に調整された共鳴フィルタのバンクを管理する:

*   **デルタ(0.5–4 Hz)**: エコシステムの巨視的「パルス」。この帯域にロックされたエージェントは長いフレーズレベルの音符を演奏する。
*   **シータ(4–8 Hz)**: 「アーティキュレーション」レート。音節的リズムと中速モチーフを統治する。
*   **アルファ(8–12 Hz)**: 「テクスチャ」レート。トレモロ、ビブラート、きらめき効果に使用される。
*   **ベータ(15–30 Hz)**: 「緊張」レート。不協和や興奮に関連する高速フラッター。

## 5.2 バイタリティと自励振動

各帯域は共振器、すなわち減衰調和振動子として実装される。重要なパラメータは`vitality`である。

*   `Vitality = 0`: 共振器は受動フィルタとして機能する。イベント(例:大音量エージェントの生成)によって励起された場合のみリンギングし、その後減衰する。
*   `Vitality > 0`: 共振器は能動ゲインを持つ。自励振動が可能で、入力がない場合でもリズミックサイクルを維持する。

これは双方向相互作用を作り出す:グローバルリズムがエージェントを駆動し(エントレインメント)、エージェントもグローバルリズムを駆動する(励起)。デルタ帯域で生成される大音量「キック」エージェントはデルタ共振器を「リンギング」させ、その帯域に結合された他のエージェントを同期させる。

## 5.3 蔵本エントレインメント

`KuramotoCore`脳は結合振動子の蔵本モデルを実装する。

$$ \frac{d\theta_i}{dt} = \omega_i + \frac{K}{N} \sum_{j=1}^N \sin(\theta_j - \theta_i) $$

Conchordalでは、「結合」$K$は他のすべてのエージェントへ直接ではなくグローバル`NeuralRhythms`へのものである(平均場近似)。

*   **感度**: 各エージェントは、どの帯域(デルタ、シータなど)をリッスンするかを決定する感度プロファイルを持つ。
*   **位相ロック**: エージェントは内部アーティキュレーション位相を共振器の位相に合わせて調整する。

これにより創発的同期が生じる。ランダムな時刻に生成されたエージェントは徐々に攻撃をデルタまたはシータ帯域のビートに整列させ、中央シーケンサーなしで一貫したリズムパターンを作り出す。

# 6. システムアーキテクチャと実装詳細

Conchordalは、リアルタイムオーディオ(レイテンシ < 10ms)の厳格な要件と重い数値解析(NSGT/畳み込み)を満たすためにRustで実装されている。アーキテクチャは並行的でロックフリーの設計パターンを使用する。

## 6.1 スレッディングモデル

アプリケーションは4つの主要なスレッドコンテキストを作成する:

1.  **オーディオスレッド(リアルタイム優先度)**:
    *   `audio/output.rs`の`cpal`によって管理される。
    *   **制約**: ブロックしてはいけない。ミューテックスなし、メモリ割り当てなし。
    *   **責任**: `Population`を反復処理し、すべてのアクティブエージェントに対して`render_wave`を呼び出し、出力をミックスし、ハードウェアバッファにプッシュする。ランドスケープの読み取り専用スナップショットから読み取る。

2.  **和声性ワーカー(バックグラウンド優先度)**:
    *   `core/stream/harmonicity.rs`で定義される。
    *   **責任**: スペクトルデータ(log2振幅スペクトル)を受信し、兄弟投影アルゴリズムを使用して和声性フィールドを計算する。
    *   **更新サイクル**: 分析が完了すると、ロックフリーSPSCチャネルを介してメインループに更新された和声性データを送信する。

3.  **粗さワーカー(バックグラウンド優先度)**:
    *   `core/stream/roughness.rs`で定義される。
    *   **責任**: オーディオチャンクを受信し、ERBドメイン畳み込みを介して粗さフィールドを計算する。
    *   **更新サイクル**: 別のSPSCチャネルを介してメインループに更新された粗さデータを送り返す。

4.  **アプリ/GUIスレッド(メイン)**:
    *   `egui`ビジュアライザと`Rhai`スクリプティングエンジンを実行する。
    *   **責任**: ユーザー入力を処理し、ランドスケープを視覚化(`ui/plots.rs`)し、シナリオスクリプトを実行する。コマンドアクション(例:`SpawnAgent`、`SetGlobalParameter`)を`Population`に送信する。
    *   **DorsalStream**: リズム分析(`core/stream/dorsal.rs`)はメインループ内で同期的に実行され、オーディオチャンクを処理して`NeuralRhythms`変調バンクのリズムエネルギーメトリクス(e_low、e_mid、e_high、flux)を抽出する。

## 6.2 データフローとダブルバッファリング

オーディオスレッドをロックせずにデータ整合性を維持するため、Conchordalはランドスケープのマルチチャネル更新戦略を使用する。

1.  **和声性ワーカー**はバックグラウンドでlog2スペクトルから和声性フィールドを構築する。
2.  **粗さワーカー**はバックグラウンドでオーディオチャンクから粗さフィールドを構築する。
3.  **メインループ**は両方のワーカーから別々のSPSCチャネルを介して更新を受信し、それらを`LandscapeFrame`にマージする。
4.  `Population`は「現在の」ランドスケープを保持する。いずれかのワーカーから新しいデータが到着すると、メインループは対応するフィールドを更新し、結合された協和を再計算する。
5.  **DorsalStream**はオーディオを同期的に処理してリズムメトリクスを更新し、`landscape.rhythm`に保存される。

この分離されたアーキテクチャは、分析ワーカーがリアルタイムよりわずかに遅れても、オーディオスレッドが常に物理学の一貫したスナップショットを見ることを保証する。各ワーカーは他をブロックせずに独自のペースで動作できる。

## 6.3 コンダクター:Rhaiによるスクリプティング

コンダクターモジュールは人間のアーティストとエコシステムの間のインターフェースとして機能する。[Rhai](https://rhai.rs/)スクリプティング言語を埋め込み、シミュレーションを制御するための高レベルAPIを公開する。

`ScriptHost`構造体は内部Rust関数をRhaiコマンドにマップする:

*   `spawn_agents(tag, method, life, count, amp)`: `Action::SpawnAgents`にマップ。確率的スポーンクラウドの定義を可能にする(例:「和声性密度を使用して200-400Hz範囲に5つのエージェントをスポーン」)。
*   `add_agent(tag, freq, amp, life)`: `Action::AddAgent`にマップ。特定の周波数に単一エージェントをスポーン。
*   `set_harmonicity(map)`: `Action::SetHarmonicity`にマップ。`mirror_weight`や`limit`などの物理パラメータのリアルタイム変調を可能にする。
*   `set_roughness_tolerance(value)`: 協和計算における粗さペナルティ重みを調整。
*   `set_habituation(weight, tau, max_depth)`: 慣れメカニズムパラメータを設定。
*   `set_rhythm_vitality(value)`: DorsalStreamリズムセクションの自励振動エネルギーを制御。
*   `wait(seconds)`: イベントループに制御を戻す非ブロック待機で、スクリプトがタイムラインを統治できるようにする。
*   `scene(name)`: 視覚化とデバッグのための名前付きシーンの開始をマーク。
*   `remove(target)`: ターゲットパターンに一致するエージェントを削除(ワイルドカード`"kick_*"`などをサポート)。

**シナリオパース**: シナリオは`.rhai`または`.json5`ファイルからロードされる。この分離により、ユーザーは「マクロ構造」(物語アーク、変化する物理法則)を作曲でき、「ミクロ構造」(特定の音符とリズム)はそれらの変化へのエージェントの適応から創発する。

# 7. ケーススタディ:創発的行動の分析

以下の例は、`samples/`ディレクトリから派生し、特定のパラメータ設定が複雑な音楽的行動にどのようにつながるかを示す。

## 7.1 ケーススタディ:自己組織化リズム(`samples/02_mechanisms/rhythmic_sync.rhai`)

このスクリプトは時間の創発的量子化を実証する。

1.  **フェーズ1(種)**: 単一の高エネルギーエージェント「Kick」が60 Hzで生成される。その周期的アーティキュレーションが`NeuralRhythms`のデルタ帯域共振器を励起する。
2.  **フェーズ2(群れ)**: ランダム位相でエージェントのクラウドが生成される。
3.  **創発**: エージェントがデルタ帯域に結合された`KuramotoCore`脳を持つため、Kickが確立したリズムを感知する。数秒間にわたり、位相がドリフトしてKickと整列する。結果は群れに明示的にプログラムされていなかった同期パルスである—結合振動子の物理学から生じた。

## 7.2 ケーススタディ:鏡像二元性(`samples/04_ecosystems/mirror_dualism.rhai`)

このスクリプトは`mirror_weight`パラメータの構造的役割を探求する。

1.  **設定**: C4(261.63 Hz)にアンカードローンが確立される。
2.  **状態A(メジャー)**: `set_harmonicity(#{ mirror: 0.0 })`。システムは共通基音投影(上音列)を使用する。協和を求めるエージェントはE4とG4周辺にクラスタ化し、Cメジャー三和音を形成する。
3.  **状態B(マイナー)**: `set_harmonicity(#{ mirror: 1.0 })`。システムは共通上音投影(下音列)に切り替わる。ランドスケープの「重力」が反転する。エージェントは今やAb3とF3(Cに対して短6度と完全4度の間隔)で安定性を見出し、フリジアン/マイナーテクスチャを作り出す。これは、Conchordalにおける「調性」が温度や重力のような操作可能な環境変数であることを示す。

## 7.3 ケーススタディ:ドリフトとフロー(`samples/04_ecosystems/drift_flow.rhai`)

このスクリプトはホップベースの移動ロジックを検証する。

1.  **アクション**: 強く不協和なエージェント(C#3)が強いアンカー(C2)の隣に配置される。
2.  **観察**: C#3エージェントはピッチで離散的なホップを行う。和声性フィールドによって「引っ張られ」、フェードアウトして近くの倍音「井戸」(おそらくE3またはG3)にスナップする。
3.  **ダイナミクス**: 慣れが有効な場合、エージェントはE3に数秒間落ち着き、その後「退屈」し(局所協和が低下)、再び新しい安定間隔を見つけるためにホップアウェイする。これにより、引力と斥力の単純な物理法則によって生成される終わりのない非反復的メロディーが生じる。

# 8. 結論

Conchordalは生体模倣計算オーディオのプルーフオブコンセプトを成功裏に確立する。音楽理論の硬直した抽象化(音符、グリッド、BPM)を連続的生理学的モデル(`Log2Space`、ERB帯域、神経振動)に置き換えることで、音楽が構築されるのではなく成長するシステムを作り出す。

`Log2Space`座標系と「兄弟投影」アルゴリズムに支えられた技術アーキテクチャは、この新しいパラダイムのための堅牢な数学的基礎を提供する。Rustの使用により、これらの複雑な生物学的シミュレーションをリアルタイムで実行でき、ALife研究とパフォーマンス的音楽楽器の間のギャップを橋渡しする。

Conchordalの将来の開発は、空間化(ランドスケープの3D空間への拡張)と進化遺伝学(成功したエージェントが`TimbreGenotype`を継承できるようにする)に焦点を当て、音と生命の類似性をさらに深める。

# 付録A:主要システムパラメータ

| Parameter | Module | Unit | Description |
| :--- | :--- | :--- | :--- |
| `bins_per_oct` | `Log2Space` | Int | 周波数グリッドの解像度(標準48-96)。 |
| `sigma_cents` | `Harmonicity` | Cents | 倍音ピークの幅。低いほど厳格なイントネーション。 |
| `mirror_weight` | `Harmonicity` | 0.0-1.0 | 上音列(メジャー)と下音列(マイナー)の重力のバランス。 |
| `habituation_tau` | `Landscape` | Seconds | 聴覚疲労/退屈の時定数。 |
| `roughness_k` | `Landscape` | Float | 適応度関数における不協和ペナルティの重み。 |
| `vitality` | `DorsalStream` | 0.0-1.0 | リズムセクションの自励振動エネルギー。 |
| `commitment` | `Individual` | 0.0-1.0 | エージェントの移動/変化への抵抗。 |

# 付録B:数学的要約

**協和適応度関数:**
$$ C(f,t) = \underbrace{H(f,t)}\_{\text{Harmonicity}} - k \cdot \underbrace{R(f,t)}\_{\text{Roughness}} - \underbrace{\int_{-\infty}^t E(f,\tau)e^{-(t-\tau)/\tau_{hab}} d\tau}\_{\text{Habituation}} $$

**和声性投影(兄弟アルゴリズム):**
$$ H[i] = (1-\alpha)\sum_m \left( \sum_k A[i+\log_2(k)] \right)[i-\log_2(m)] + \alpha \sum_m \left( \sum_k A[i-\log_2(k)] \right)[i+\log_2(m)] $$

**粗さ畳み込み:**
$$ R(z) = \int A(\tau) \cdot K_{plomp}(|z-\tau|_{ERB}) d\tau $$