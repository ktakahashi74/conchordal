+++
title = "Technical Note: The Physics of Conchordal"
description = "A deep dive into the psychoacoustic algorithms, logarithmic signal processing, and artificial life strategies powering the Conchordal ecosystem."
template = "page.html"
[extra]
source_commit = "272f31a"
author = "Koichi Takahashi"
last_updated = "2026-01-19"
source_version = "0.2.0"
source_snapshot = "2026-01-19T00:00:00+09:00"
generated_by = "claude-opus-4-5-20251101"
+++

# 1. はじめに：生物音響パラダイム

Conchordal は、生成音楽および計算論的オーディオの既存の規範から根本的に逸脱したシステムである。従来のシステムが記号操作—量子化されたピッチのグリッド（MIDI、平均律）や離散化された時間（BPM、小節）—に依存するのに対し、Conchordal は聴覚知覚の連続的かつ生物学的に基盤を持つシミュレーションとして機能する。本システムは、音楽構造が抽象的な作曲の産物ではなく、音響的生存の創発的特性であるという立場をとる。

本技術ノートは、システムのアーキテクチャ、信号処理アルゴリズム、および人工生命戦略に関する包括的なリファレンスとして機能する。Conchordal が心理音響学の原理—特に臨界帯域理論、仮想ピッチ知覚、神経同期—を自律的エコシステムのダイナミクスとどのように統合するかを詳述する。この環境において、音は生きた有機体、すなわち代謝、感覚処理能力、そして敵対的なスペクトル地形を navigateする自律性を持つ「Individual（個体）」として扱われる。

システムの創発的挙動は、統一された適応度関数によって駆動される：協和（Consonance）の追求である。Conchordal エコシステム内のエージェントは、あらかじめ書かれたスコアに従わない。代わりに、環境を継続的に分析し、「スペクトル快適度」—感覚的なラフネスの最小化として定義される—と「調和安定性」—仮想基音の強度の最大化—を最大化する。その結果、ハーモニー、リズム、音色が決定論的シーケンシングではなく物理法則の相互作用を通じて有機的に進化する、自己組織化するサウンドスケープが生まれる。

本文書では、Conchordal アーキテクチャの3つの基盤的柱を探求する：

1.  **心理音響座標系**：線形ヘルツと整数MIDIノートを置き換える `Log2Space` とERBスケールの数学的フレームワーク。
2.  **認知的ランドスケープ**：生のオーディオストリームからラフネス（$R$）と調和性（$H$）フィールドを計算するリアルタイムDSPパイプライン。
3.  **ライフエンジン**：オーディオエンティティの代謝、移動、神経同期を統括するエージェントベースモデル。

# 2. 心理音響座標系

Conchordal における重要な革新は、内部処理において線形周波数スケール（$f$）を拒否したことである。人間の聴覚知覚は本質的に対数的であり、ピッチ間隔の知覚は周波数差ではなく周波数比に基づく。これを正確かつ効率的にモデル化するため、Conchordal は計算グリッドを蝸牛のトノトピックマップに整合させるカスタム座標系 `Log2Space` を確立する。

## 2.1 Log2 Space の基盤

`Log2Space` 構造体は、システム内のすべてのスペクトル分析、カーネル畳み込み、およびエージェント位置決めの基盤として機能する。物理的な周波数ドメイン（Hz単位の $f$）を知覚的な対数ドメイン（$l$）にマッピングする。

### 2.1.1 数学的定義

ヘルツから内部対数座標への変換は、周波数の底2対数として定義される。この選択は意図的である：底2では、1.0の増分がピッチ知覚における最も基本的な音程であるオクターブに正確に対応する。

$$ l(f) = \log_2(f) $$

オーディオスレッドの合成パラメータを導出するために使用される逆変換は：

$$ f(l) = 2^l $$

座標空間は、解像度パラメータ `bins_per_oct`（$B$）によって定義されるグリッドに離散化される。このパラメータはシミュレーションの粒度を決定する。$B=48$ または $B=96$ の典型的な値は、連続的なピッチグライドと微分音的な抑揚に十分なセミトーン以下の解像度を提供する。ステップサイズ $\Delta l$ は全スペクトル範囲で一定である：

$$ \Delta l = \frac{1}{B} $$

### 2.1.2 グリッド構築とインデックス

`Log2Space` 構造体は、設定された範囲 $[f_{min}, f_{max}]$ にわたるすべてのビンの中心周波数を事前計算する。ビン数 $N$ は完全なカバレッジを確保するように決定される：

$$ N = \lfloor \frac{\log_2(f_{max}) - \log_2(f_{min})}{\Delta l} \rfloor + 1 $$

システムはDSP操作中の $O(1)$ アクセスのために2つの並列ベクトルを維持する：

*   `centers_log2`：対数座標 $l_i = \log_2(f_{min}) + i \cdot \Delta l$。
*   `centers_hz`：事前計算された線形周波数 $f_i = 2^{l_i}$。

この事前計算はリアルタイム性能に不可欠であり、スペクトルカーネルの内部ループ内でコストのかかる `log2` および `pow` 呼び出しを除去する。メソッド `index_of_freq(hz)` は量子化ロジックを提供し、任意の浮動小数点周波数を最も近いビンインデックスにマッピングする。

## 2.2 定Q帯域幅特性

`Log2Space` は本質的に、スペクトル全体にわたって定Q（Constant Quality Factor）特性を強制する。信号処理の用語では、$Q$ は中心周波数と帯域幅の比として定義される：$Q = f / \Delta f$。

線形システム（標準FFTなど）では、$\Delta f$ が一定であり、$Q$ は周波数とともに増加する。`Log2Space` では、$i$ 番目のビンの帯域幅 $\Delta f_i$ は中心周波数 $f_i$ に比例してスケーリングする。この特性は人間の聴覚システムの周波数選択性を模倣しており、耳が周波数を分解する能力は（絶対Hz単位で）周波数が増加するにつれて減少する。この整合により、Conchordal は計算リソースを効率的に配分できる—高周波数では高い時間解像度を、低周波数では高いスペクトル解像度を—手動のマルチレート処理なしに。

## 2.3 等価矩形帯域幅（ERB）スケール

`Log2Space` はピッチ関係（オクターブ、倍音）を扱うが、低周波数では純粋な対数マッピングが示唆するよりも広い耳の臨界帯域を完全にモデル化するわけではない。感覚的ラフネス（不協和）を正確に計算するために、Conchordal は Glasberg & Moore（1990）モデルに基づく等価矩形帯域幅（ERB）スケールを実装する。

`core/erb.rs` モジュールは、ラフネスカーネルで使用される変換関数を提供する。周波数 $f$（Hz）からERBレート単位 $E$ への変換は次式で与えられる：

$$ E(f) = 21.4 \log_{10}(0.00437f + 1) $$

周波数 $f$ における臨界帯域の帯域幅は：

$$ BW_{ERB}(f) = 24.7(0.00437f + 1) $$

このスケールは `Log2Space` とは異なる。`Log2Space` がピッチと調和性のドメイン（関係がオクターブ不変）であるのに対し、ラフネス計算は干渉を評価するためにスペクトルエネルギーをERBドメインにマッピングすることを必要とする。システムは実質的にスペクトルの二重ビューを維持する：倍音テンプレート用の厳密に対数的なものと、不協和評価用の心理音響的なもの。

# 3. 聴覚ランドスケープ：環境の分析

「ランドスケープ」は Conchordal の中心的なデータ構造である。すべてのエージェントの共有環境として機能し、各周波数ビンの心理音響的「ポテンシャル」を表す動的スカラーフィールドである。エージェントは互いに直接相互作用せず、全集団のスペクトルエネルギーを集約するランドスケープと相互作用する。これによりシミュレーションの複雑さがエージェント数から切り離される（$O(N)$ vs $O(N^2)$）。

ランドスケープは各オーディオフレーム（またはブロック）ごとに分析ワーカーによって更新される。2つの主要な指標を合成する：

*   **ラフネス（$R$）**：近接する部分音間の急速なうなりによって引き起こされる感覚的不協和。
*   **調和性（$H$）**：仮想ピッチの強度とスペクトル周期性の尺度。

両指標は結合前に $[0, 1]$ 範囲に正規化される。正味の協和度（$C$）は符号付き差分として計算され、その後再スケーリングされる：

$$ C_{signed} = \text{clip}(H_{01} - w_r \cdot R_{01},\; -1,\; 1) $$

$$ C_{01} = \frac{C_{signed} + 1}{2} $$

ここで $w_r$ は `roughness_weight` パラメータ（デフォルト 1.0）である。個々のエージェントは独自の知覚コンテキスト（`PerceptualContext`）を維持し、エージェントごとの飽きと親しみを追跡して、ピッチ選択時に追加のスコア調整を提供する。

## 3.1 非定常ガボール変換（NSGT）

`Log2Space` をスペクトルデータで満たすために、Conchordal は非定常ガボール変換（NSGT）のカスタム実装を使用する。固定ウィンドウサイズを使用する短時間フーリエ変換（STFT）とは異なり、NSGT はセクション2.2で導出した定Q特性を維持するために、ウィンドウ長 $L$ を周波数に反比例して変化させる。

### 3.1.1 カーネルベースのスペクトル分析

`core/nsgt_kernel.rs` の実装は、この変換を効率的に実行するためにスパースカーネルアプローチを利用する。各対数周波数帯域 $k$ に対して、時間ドメインカーネル $h_k$ が事前計算される。このカーネルは、帯域の中心周波数 $f_k$ での複素正弦波と、長さ $L_k \approx Q \cdot f_s / f_k$ の周期的ハン窓 $w_k$ を組み合わせる。

$$ h_k[n] = w_k[n] \cdot e^{-j 2\pi f_k n / f_s} $$

これらのカーネルは初期化時に周波数ドメイン（$K_k[\nu]$）に変換される。性能を最適化するために、システムはこれらの周波数カーネルをスパース化し、有意なエネルギーを持つビンのみを格納する。

ランタイム中、システムは入力オーディオバッファに対して単一のFFTを実行してスペクトル $X[\nu]$ を取得する。帯域 $k$ の複素係数 $C_k$ は、周波数ドメインでの内積を介して計算される：

$$ C_k = \frac{1}{N_{fft}} \sum_{\nu} X[\nu] \cdot K_k^*[\nu] $$

この「1回のFFT、多数のカーネル」アプローチにより、Conchordal は20Hzから20kHzをカバーする高解像度の対数間隔スペクトルを、各帯域に対して個別のDFTを計算したり再帰フィルタバンクを使用したりする計算オーバーヘッドなしに生成できる。

### 3.1.2 リアルタイム時間平滑化

生のスペクトル係数 $C_k$ は、オーディオ入力の確率的性質（特にノイズベースのエージェント）により高い分散を示す。エージェントがサンプリングする安定したフィールドを作成するために、`RtNsgtKernelLog2` 構造体はNSGTを時間平滑化レイヤーでラップする。

これは帯域ごとのリーキー積分器（指数平滑化）を実装する。重要なのは、時定数 $\tau$ が周波数依存であることである。ゆっくり進化する低周波数はより長い $\tau$ で平滑化され、過渡的詳細を運ぶ高周波数はより短い $\tau$ を持つ。

$$ y_k[t] = (1 - \alpha_k) \cdot |C_k[t]| + \alpha_k \cdot y_k[t-1] $$

ここで平滑化係数 $\alpha_k$ はフレーム間隔 $\Delta t$ から導出される：

$$ \alpha_k = e^{-\Delta t / \tau(f_k)} $$

これは耳の「積分時間」をモデル化し、ランドスケープが瞬間的な信号パワーではなく心理音響的知覚を反映することを保証する。

## 3.2 ラフネス（$R$）計算：Plomp-Levelt モデル

ラフネスは、同じ臨界帯域内に入るが単一のトーンとして知覚されるほど十分に近くないスペクトル成分の干渉によって引き起こされる「粗さ」または「ブンブン音」の感覚である（うなり）。Conchordal は ERB ドメインでの畳み込みを介して Plomp-Levelt モデルの変形を実装する。

### 3.2.1 干渉カーネル

計算の核心は、`core/roughness_kernel.rs` で定義されるラフネスカーネルである。このカーネル $K_{rough}(\Delta z)$ は、$\Delta z$ ERB 離れた2つの部分音間の干渉曲線をモデル化する。曲線は部分音が分離するにつれて急速に上昇するペナルティを作り、約0.25 ERB（最大ラフネス）でピークに達し、その後さらに分離するにつれて減衰する。

実装はこの形状を生成するためにパラメータ化された関数 `eval_kernel_delta_erb` を使用する：

$$ g(\Delta z) = e^{-\frac{\Delta z^2}{2\sigma^2}} \cdot (1 - e^{-(\frac{\Delta z}{\sigma_{suppress}})^p}) $$

第2項は $\Delta z \to 0$ のときにカーネルがゼロになることを保証する抑制因子であり、単一の純音が自己ラフネスを生成することを防ぐ。

### 3.2.2 畳み込みアプローチ

すべてのスペクトルビンに対してペアワイズでラフネスを計算すること（$N^2$ 複雑度）は、リアルタイムアプリケーションには計算上禁止的である。Conchordal はラフネス計算を線形畳み込みとして扱うことでこれを解決する。

1.  **マッピング**：NSGTからの対数間隔振幅スペクトルは、線形ERBグリッドにマッピング（または補間）される。
2.  **畳み込み**：この密度 $A(z)$ は、事前計算されたラフネスカーネル $K_{rough}$ と畳み込まれる。

$$ R_{shape}(z) = (A * K_{rough})(z) = \int A(z-\tau) K_{rough}(\tau) d\tau $$

結果 $R_{shape}(z)$ は周波数 $z$ における生の「ラフネス形状」を表す。これを正規化された適応度信号に変換するために、Conchordal は生理学的飽和マッピングを適用する。

### 3.2.3 生理学的飽和マッピング

畳み込みからの生のラフネス値は無限の範囲を持つ。ハードクランピングではなく、Conchordal は聴覚知覚の圧縮非線形性をモデル化する飽和曲線を使用する。このマッピングは参照正規化されたラフネス比を $[0, 1]$ 範囲に変換する。

**参照正規化**：システムは「典型的な」ラフネスレベルを表す参照値 $r_{ref,peak}$ と $r_{ref,total}$ を維持する。参照正規化された比は：

$$ x_{peak}(u) = \frac{R_{shape}(u)}{r_{ref,peak}} $$

$$ x_{total} = \frac{R_{shape,total}}{r_{ref,total}} $$

**飽和パラメータ**：パラメータ `roughness_k`（$k > 0$）は飽和曲線のショルダーを制御する。参照比 $x = 1$ は次にマッピングされる：

$$ R_{ref} = \frac{1}{1+k} $$

より大きな $k$ は同じ入力比に対して $R_{01}$ を減少させ、システムをラフネスに対してより寛容にする。

**区分的飽和マッピング**：正規化されたラフネス $R_{01}$ は参照正規化された比 $x$ から次のように計算される：

$$
R_{01}(x; k) = \begin{cases}
0 & \text{if } x \leq 0 \\
x \cdot \frac{1}{1+k} & \text{if } 0 < x < 1 \\
1 - \frac{k}{x+k} & \text{if } x \geq 1
\end{cases}
$$

この関数は $x = 1$ で連続（両方の分岐が $\frac{1}{1+k}$ を与える）であり、$x \to \infty$ で漸近的に1に飽和する。区分的構造は、低ラフネスに対する線形応答（感度を維持）を確保しつつ、極端な値を圧縮する（飽和を防ぐ）。

**数値的安全性**：実装はエッジケースを堅牢に処理する：

*   $x = \text{NaN} \to 0$
*   $x = +\infty \to 1$
*   $x = -\infty \to 0$
*   非有限の $k$ は $10^{-6}$ として扱われる

協和を求めるエージェントは積極的に $R_{01}$ フィールドのピークを避ける。

## 3.3 調和性（$H$）：Sibling Projection アルゴリズム

ラフネスがエージェントを不協和から遠ざける（分離）一方で、調和性（$H$）はエージェントを融合へ—凝集したコードと音色の創造へ—と駆り立てる。Conchordal は、このフィールドを計算するために「Sibling Projection」と呼ばれる新しいアルゴリズムを導入する。このアルゴリズムは、脳の「共通基音」検出（仮想ピッチ）のメカニズムを完全に周波数ドメインで近似する。

### 3.3.1 コンセプト：仮想基音

アルゴリズムは、周波数 $f$ の任意のスペクトルピークが、その下倍音（$f/2, f/3, f/4 \dots$）に基音（ルート）の潜在的な存在を暗示すると仮定する。複数のスペクトルピークが共通の下倍音を共有する場合、その下倍音は強い「仮想基音」を表す。

### 3.3.2 2パス投影

アルゴリズムは `Log2Space` スペクトル上で2パスで動作し、対数グリッドの整数特性を利用する：

1.  **下方投影（基音探索）**：現在のスペクトルエンベロープが下方に「スミア」される。エネルギーを持つすべてのビン $i$ に対して、アルゴリズムは整数 $k \in \{1, 2, \dots, N\}$ に対してビン $i - \log_2(k)$ にエネルギーを追加する。

    $$ Roots[i] = \sum_k A[i + \log_2(k)] \cdot w_k $$

    ここで、$w_k$ は倍音インデックス $k$ とともに減衰する重み係数（例：$k^{-\rho}$）であり、低い倍音が高い倍音よりも強くその基音を暗示することを反映する。結果 `Roots` は各周波数における仮想ピッチの強度を記述する。

2.  **上方投影（倍音共鳴）**：システムは次に `Roots` スペクトルを上方に投影する。強い基音が $f_r$ に存在する場合、そのすべての自然倍音（$f_r, 2f_r, 3f_r \dots$）に安定性を暗示する。

    $$ H[i] = \sum_m Roots[i - \log_2(m)] \cdot w_m $$

**創発的調性安定性**：200 Hzの単一トーンを持つ環境を考える。

*   **ステップ1（下方）**：100 Hz（$f/2$）、66.6 Hz（$f/3$）、50 Hz（$f/4$）などに基音を投影する。
*   **ステップ2（上方）**：100 Hzの基音は100、200、300、400、500... Hzに安定性を投影する。
    *   300 Hzは100 Hz基音の完全5度。
    *   500 Hzは100 Hz基音の長3度。

したがって、西洋音楽理論のハードコードされた知識なしに、システムは長3度と完全5度の関係に安定性ピークを自然に生成する。これは単に倍音列の物理学の帰結である。200 Hzのエージェントは300 Hzと500 Hzに「重力井戸」を作り、他のエージェントに長三和音を形成するよう促す。

### 3.3.3 鏡像双対性：上倍音 vs. 下倍音

`core/harmonicity_kernel.rs` の実装には、深遠なパラメータ `mirror_weight`（$\alpha$）が含まれる。このパラメータは2つの異なる投影パスをブレンドする：

*   **パスA（上倍音/長調）**：上述した標準的な「下→上」投影。上倍音列に基づく重力を作り、長調を好む。
*   **パスB（下倍音/短調）**：逆の「上→下」投影。共通の上倍音を見つけ、下倍音を投影する。これはパスAの理論的双対であり、短調またはフリギア調性（下倍音列）を好む。

$$ H_{final} = (1-\alpha)H_{overtone} + \alpha H_{undertone} $$

`mirror_weight` を変調することで、ユーザーは宇宙の基本物理を長調中心から短調中心へ連続的に変形させ、それに応じてエコシステムがどのように再組織化するかを観察できる。

# 4. ライフエンジン：エージェントと自律性

「ライフエンジン」は、DSPランドスケープの上で実行されるエージェントベースのシミュレーションレイヤーである。「Individual」の集団を管理し、そのライフサイクル、感覚処理、発声タイミング、およびオーディオ合成を処理する。

## 4.1 概要：Individual アーキテクチャ

`Individual` 構造体（`life/individual.rs`）はエコシステムの原子単位である。そのアーキテクチャは、階層的なコントロール構造を通じて挙動がパラメータ化される**コントロール駆動設計**に基づく。

### 4.1.1 コアコンポーネント

| コンポーネント | 型 | 責務 |
|-----------|------|----------------|
| `base_control` | `AgentControl` | スポーン時に設定された元のコントロールパラメータ |
| `effective_control` | `AgentControl` | 現在のアクティブなコントロール（更新後にbaseと異なる場合がある） |
| `articulation` | `ArticulationWrapper` | リズム、ゲーティング、エンベロープダイナミクス |
| `pitch_ctl` | `PitchController` | 統合された知覚コンテキストを持つピッチターゲティング |
| `phonation_engine` | `PhonationEngine` | ノートタイミング、クロックソース、社会的結合 |
| `body` | `AnySoundBody` | 音生成（波形合成、スペクトル投影） |

### 4.1.2 AgentControl 階層

`AgentControl` 構造体（`life/control.rs`）は、すべてのエージェント挙動の中心的な設定インターフェースとして機能する：

```
AgentControl
├── body: BodyControl
│   ├── method: BodyMethod (Sine | Harmonic)
│   ├── amp: f32
│   └── timbre: TimbreControl
│       ├── brightness: f32
│       ├── inharmonic: f32
│       ├── width: f32
│       └── motion: f32
├── pitch: PitchControl
│   ├── mode: PitchMode (Free | Lock)
│   ├── freq: f32
│   ├── range_oct: f32
│   ├── gravity: f32
│   ├── exploration: f32
│   └── persistence: f32
├── phonation: PhonationControl
│   ├── type: PhonationType (Interval | Clock | Field | Hold | None)
│   ├── density: f32
│   ├── sync: f32
│   ├── legato: f32
│   └── sociality: f32
└── perceptual: PerceptualControl
    ├── enabled: bool
    ├── adaptation: f32
    ├── novelty_bias: f32
    └── self_focus: f32
```

### 4.1.3 固定 vs. 可変プロパティ

重要な設計原則は、**固定**プロパティと**可変**プロパティの区別である：

| プロパティ | 可変性 | 設定タイミング | 説明 |
|----------|------------|--------|-------------|
| `fixed_body_method` | 不変 | スポーン | `Sine` または `Harmonic` — スポーン後は変更不可 |
| `fixed_phonation_type` | 不変 | スポーン | 発声タイプ — スポーン後は変更不可 |
| `amp`, `freq`, `timbre.*` | 可変 | ランタイム | `apply_update()` で更新可能 |
| `brain`, `metabolism`, `adsr` | 不変 | スポーン | スクリプティングAPIでスポーン前に設定が必要 |

この分離により、基本的なアーキテクチャ決定（合成方法、発声モデル）は誕生時に決定され、表現パラメータ（振幅、周波数、音色）はリアルタイムで変調できることが保証される。

Individual は統合レイヤーとして機能する：ライフサイクル（代謝、エネルギー）を調整し、コントロールプレーン信号（`PlannedPitch`）を介してコアを調整し、コアを直接結合せずに状態遷移を管理する。

## 4.2 SoundBody：アクチュエータ

`SoundBody` トレイト（`life/sound_body.rs`）は音生成機能を定義する。2つの実装が存在する：

### 4.2.1 SineBody

純粋な正弦波オシレータ。最小限のパラメータ：
- `freq_hz`：基本周波数
- `amp`：振幅
- `audio_phase`：現在のオシレータ位相

### 4.2.2 HarmonicBody と TimbreGenotype

基音と設定可能な部分音を持つ複合トーンを合成する。`TimbreGenotype` 構造体は音色DNAをエンコードする：

| パラメータ | 型 | 説明 |
|-----------|------|-------------|
| `mode` | `HarmonicMode` | `Harmonic`（整数倍：$1, 2, 3...$）または `Metallic`（非整数：$k^{1.4}$） |
| `stiffness` | `f32` | 非調和性係数；$f_k = k \cdot (1 + \text{stiffness} \cdot k^2)$ で部分音列を引き伸ばす |
| `brightness` | `f32` | スペクトル傾斜；部分音振幅は $k^{-\text{brightness}}$ で減衰 |
| `comb` | `f32` | 偶数倍音減衰（0–1）；中空の音色を作る |
| `damping` | `f32` | エネルギー依存の高周波減衰；低エネルギーで高い部分音がより速く減衰 |
| `vibrato_rate` | `f32` | ピッチ変調用LFO周波数（Hz） |
| `vibrato_depth` | `f32` | ビブラートの範囲（周波数の割合） |
| `jitter` | `f32` | $1/f$ ピンクノイズFM強度；有機的な揺らぎを追加 |
| `unison` | `f32` | コーラス効果用のデチューン量（0 = 単一ボイス） |

**スペクトル投影**：両ボディは `project_spectral_body()` を実装し、エネルギー分布をランドスケープ計算用の `Log2Space` グリッドに書き戻す。これによりシステムは各エージェントのスペクトルフットプリントを「見る」ことができる。

## 4.3 行動コアスタック

挙動は、エージェント行動の異なる側面を処理する専門化されたコアに組織化される。

### 4.3.1 ArticulationCore（いつ/ゲート）

`life/articulation_core.rs` で定義。リズム、ゲーティング、エンベロープダイナミクスを管理する。スクリプトの `brain` パラメータで選択される3つのバリアント：

| バリアント | スクリプト名 | 説明 | 主要パラメータ |
|---------|-------------|-------------|----------------|
| `KuramotoCore` | `"entrain"` | `NeuralRhythms` への蔵本スタイルの結合 | `lifecycle`, `rhythm_freq`, `rhythm_sensitivity` |
| `SequencedCore` | `"seq"` | 固定時間エンベロープ | `duration`（秒） |
| `DroneCore` | `"drone"` | ゆっくりした振幅スウェイを持つ連続トーン | `sway`（変調深度） |

**ArticulationWrapper**：コアを `PlannedGate` 構造体でラップし、ピッチ変更時のフェードイン/フェードアウト遷移を管理する。ゲート値（0–1）は振幅に乗算され、スムーズな遷移を保証する。

**ArticulationSignal**：アーティキュレーション処理の出力：
- `amplitude`：現在のエンベロープレベル
- `is_active`：エージェントが現在発音中かどうか
- `relaxation`：ビブラート/ユニゾン拡張の変調信号
- `tension`：ジッター強化の変調信号

### 4.3.2 PitchController（どこ）

`life/pitch_controller.rs` で定義。`PitchController` はピッチターゲティングと知覚コンテキストを統合コンポーネントに統合する：

```
PitchController
├── core: AnyPitchCore (HillClimb アルゴリズム)
├── perceptual: PerceptualContext (飽き/親しみ)
├── target_pitch_log2: f32
├── integration_window: f32
└── perceptual_enabled: bool
```

コントローラは `PitchControl` パラメータを通じてピッチ挙動を公開する：

| パラメータ | デフォルト | 説明 |
|-----------|---------|-------------|
| `mode` | `Free` | `Free`（自律移動）または `Lock`（固定周波数） |
| `freq` | 220.0 | 中心周波数（Free）またはロック周波数（Lock） |
| `range_oct` | 6.0 | オクターブ単位の最大探索範囲 |
| `gravity` | 0.5 | 音域重力（0 = なし、1 = 中心への強い引力） |
| `exploration` | 0.0 | ランダム探索確率（0–1） |
| `persistence` | 0.5 | 満足時の移動への抵抗（0–1） |

**スコアリング**：各候補ピッチは次のように評価される：

$$ \text{score} = C_{01} - d_{\text{penalty}} - g_{\text{tessitura}} + \Delta s_{\text{perceptual}} $$

`TargetProposal` 出力には `target_pitch_log2` と改善強度を反映する `salience` スコア（0–1）が含まれる。

## 4.4 PerceptualContext：主観的適応

`life/perceptual.rs` で定義され、`PitchController` に統合される。エージェントごとの馴化と選好をモデル化し、エージェントが局所的最適位置に「停滞」することを防ぐ。

コンテキストは周波数ビンごとに2つのリーキー積分器を維持する：
- **h_fast**：短期露出（飽きアキュムレータ）
- **h_slow**：長期露出（親しみアキュムレータ）

エージェントの `AgentControl` 内の `PerceptualControl` で制御される：

| コントロールパラメータ | マッピング先 | 説明 |
|-------------------|-----------|-------------|
| `enabled` | — | 知覚適応の有効化/無効化 |
| `adaptation` | `tau_fast`, `tau_slow` | 減衰の時定数（0 = 速い、1 = 遅い） |
| `novelty_bias` | `w_boredom` | 飽きペナルティの重み |
| `self_focus` | `rho_self` | 自己注入比 |

内部パラメータ（コントロールから導出）：

| パラメータ | デフォルト | 説明 |
|-----------|---------|-------------|
| `tau_fast` | 0.5 s | 飽き減衰の時定数 |
| `tau_slow` | 20.0 s | 親しみ減衰の時定数 |
| `w_boredom` | 1.0 | 飽きペナルティの重み |
| `w_familiarity` | 0.2 | 親しみボーナスの重み |
| `rho_self` | 0.15 | 自己注入比（エージェント自身の位置がどれだけ寄与するか） |
| `boredom_gamma` | 0.5 | 飽きの曲率指数（$h_{\text{fast}}^\gamma$） |
| `self_smoothing_radius` | 1 | 自己注入の空間平滑化半径 |
| `silence_mass_epsilon` | 1e-6 | 無音検出の閾値 |

**スコア調整**：

$$ \Delta s = w_{\text{familiarity}} \cdot h_{\text{slow}} - w_{\text{boredom}} \cdot h_{\text{fast}}^{\gamma} $$

これにより、エージェントは馴染みのある領域に引き寄せられるが、訪問過多の場所からは押し出されるダイナミクスが生まれる。

## 4.5 PhonationEngine：タイミングと発声

`life/phonation_engine.rs` で定義。PhonationEngine はエージェントが*いつ*発声するかを統括し、ノートオンセット、デュレーション、他のエージェントとの協調を管理する。

### 4.5.1 発声タイプ

発声挙動はエージェントのコントロール内の `PhonationControl.type` で選択される：

| タイプ | スクリプト名 | 説明 |
|------|-------------|-------------|
| `Interval` | `"decay"` | 減衰エンベロープを伴う確率的オンセット |
| `Clock` | — | クロック同期オンセット |
| `Field` | `"grain"` | グラニュラー、フィールド応答発声 |
| `Hold` | `"hold"` | ライフサイクルごとに一度持続；density/sync/legatoを無視 |
| `None` | — | サイレントエージェント（発声なし） |

### 4.5.2 PhonationControl パラメータ

`PhonationControl` 構造体は発声挙動の高レベル制御を提供する：

| パラメータ | デフォルト | 範囲 | 説明 |
|-----------|---------|-------|-------------|
| `type` | `Interval` | — | 発声モデル（上記参照） |
| `density` | 0.5 | 0–1 | ノート密度/オンセットレート |
| `sync` | 0.5 | 0–1 | シータリズムへの同期 |
| `legato` | 0.5 | 0–1 | ノートデュレーション（0 = スタッカート、1 = レガート） |
| `sociality` | 0.0 | 0–1 | 社会的結合強度 |

### 4.5.3 社会的結合

`SocialConfig` はエージェントが集団の発声密度に応答できるようにする：

| パラメータ | 説明 |
|-----------|-------------|
| `coupling` | 社会的影響の強度（0 = 独立） |
| `bin_ticks` | 密度測定の時間解像度 |
| `smooth` | 密度トレースの平滑化係数 |

**SocialDensityTrace**（`life/social_density.rs`）：集団の最近のオンセット密度を追跡し、エージェントが同期したり混雑した瞬間を避けたりできるようにする。

グローバル結合はスクリプティングAPIの `set_global_coupling(value)` で設定できる。

## 4.6 ライフサイクルと代謝

エージェントは生物学的代謝をモデル化したエネルギーダイナミクスによって統括される。`LifecycleConfig`（`life/lifecycle.rs`）は2つのモードを定義する：

### 4.6.1 Decay モード

過渡的な音（プラック、打楽器）をモデル化：

| パラメータ | デフォルト | 説明 |
|-----------|---------|-------------|
| `initial_energy` | 1.0 | 開始エネルギープール |
| `half_life_sec` | — | 指数減衰の半減期 |
| `attack_sec` | 0.01 | アタックランプデュレーション |

エネルギーは次のように進化する：$E(t) = E_0 \cdot e^{\lambda t}$ ここで $\lambda = \ln(0.5) / t_{1/2}$

### 4.6.2 Sustain モード

代謝フィードバックを持つ持続音をモデル化：

| パラメータ | デフォルト | 説明 |
|-----------|---------|-------------|
| `initial_energy` | 1.0 | 開始エネルギープール |
| `metabolism_rate` | — | 毎秒のエネルギー消費 |
| `recharge_rate` | 0.5 | エネルギー回復レート（協和度依存） |
| `action_cost` | 0.02 | 発声ごとのエネルギーコスト |
| `envelope` | — | ADSR設定（`attack_sec`, `decay_sec`, `sustain_level`） |

**ブレスゲインフィードバック**：`breath_gain` パラメータ（スポーン時に `breath_gain_init` で設定）は、協和度がエネルギー回復にどれだけ寄与するかを決定する。不協和な領域のエージェントは「飢える」一方、協和な領域のエージェントは「栄養を得る」。

これによりダーウィン的圧力が生まれる：**協和者の生存**。調和関係を見つけたエージェントだけが聞こえるまで生き残るため、音楽構造が創発する。

## 4.7 ピッチリターゲティングと制御フロー

エージェントは適応度を改善するために周波数空間を移動する。制御レート更新フローは `tick_control()` によって調整される：

```
tick_control(dt_sec, rhythms, landscape, global_coupling)
└── update_articulation(dt_sec, rhythms, landscape, global_coupling)
    ├── update_pitch_target(rhythms, dt_sec, landscape)
    │   └── pitch_ctl.update_pitch_target(...)
    ├── update_articulation_autonomous(dt_sec, rhythms)
    │   └── articulation.update_gate(&planned, rhythms, dt_sec)
    └── tick_articulation_lifecycle(dt_sec, rhythms, landscape, global_coupling)
        └── articulation.process(consonance, rhythms, dt_sec, global_coupling)
```

### 4.7.1 ピッチモード：Free vs. Lock

`PitchControl.mode` はピッチ挙動を決定する：

| モード | 挙動 |
|------|----------|
| `Free` | ヒルクライムアルゴリズムによる自律的ピッチ探索 |
| `Lock` | 固定周波数；ゲートは常に開；ピッチ探索なし |

`mode` が `Lock` の場合（スクリプトで `.freq()` または `.place()` を使用すると自動的に設定）、エージェントはフェード遷移なしでターゲット周波数に即座にスナップする。

### 4.7.2 ホップポリシー（Free モード）

`Free` モードでは、ピッチ移動は連続的なポルタメントではなく離散的な**ホップ**を使用する：

1. **提案**：`PitchController` は候補を評価し、ターゲットピッチとサリエンスを持つ `TargetProposal` を返す。

2. **ゲート協調**：`update_articulation_autonomous()` は `PlannedPitch` を構築する：
   - `target_pitch_log2`：次の意図されたピッチ
   - `jump_cents_abs`：ターゲットまでの距離（セント）
   - `salience`：改善強度（0–1）

3. **フェードアウト**：`jump_cents_abs > 10`（移動閾値）のときゲートが閉じる

4. **スナップ**：ゲート < 0.1 のとき、`body.set_pitch_log2()` がターゲットに更新

5. **フェードイン**：ゲートが再び開き、新しいピッチが鳴る

**順序**：スナップ時、ピッチは協和度評価の*前に*更新され、ランドスケープスコアが実際に鳴っている周波数を反映することを保証する。これらのタイミングセンシティブな遷移はリグレッションテストで保護されている。

### 4.7.3 apply_update() によるライブ更新

`apply_update(&ControlUpdate)` メソッドは可変パラメータのランタイム変更を可能にする：

| 更新可能 | フィールド | 制約 |
|-----------|-------|------------|
| 振幅 | `amp` | [0, 1] にクランプ |
| 周波数 | `freq` | [1, 20000] Hz にクランプ；`mode = Lock` を強制 |
| ブライトネス | `timbre_brightness` | [0, 1] にクランプ |
| インハーモニック | `timbre_inharmonic` | [0, 1] にクランプ |
| ワイズ | `timbre_width` | [0, 1] にクランプ |
| モーション | `timbre_motion` | [0, 1] にクランプ |

**重要**：更新は `body.method` や `phonation.type` を変更できない。これらは `ensure_fixed_kinds()` で検証され、不一致の場合はエラーを返す。

# 5. 時間ダイナミクス：神経リズム

Conchordal はマスタークロックやメトロノームの概念を排除する。代わりに、時間は神経振動（脳波）に着想を得た連続的な変調フィールドによって構造化される。これは「空間」ランドスケープの「時間」等価物である。

## 5.1 変調バンク

`NeuralRhythms` 構造体は、生理学的周波数帯域に同調した共振フィルタのバンクを管理する：

*   **デルタ（0.5–4 Hz）**：エコシステムのマクロスコピックな「パルス」。このバンドにロックされたエージェントは長いフレーズレベルのノートを演奏する。
*   **シータ（4–8 Hz）**：「アーティキュレーション」レート。音節リズムと中速モチーフを統括する。
*   **アルファ（8–12 Hz）**：「テクスチャ」レート。トレモロ、ビブラート、シマリング効果に使用。
*   **ベータ（15–30 Hz）**：「緊張」レート。不協和や興奮に関連する高速フラッター。

## 5.2 バイタリティと自励振動

各バンドはレゾネーター、減衰調和振動子として実装される。重要なパラメータは `vitality` である。

*   `Vitality = 0`：レゾネーターはパッシブフィルタとして機能する。イベント（例：大きなエージェントのスポーン）によって励起されたときのみリングし、その後減衰する。
*   `Vitality > 0`：レゾネーターはアクティブゲインを持つ。入力がなくてもリズムサイクルを維持して自励振動できる。

これにより双方向の相互作用が生まれる：グローバルリズムがエージェントを駆動し（同期）、エージェントもグローバルリズムを駆動する（励起）。デルタバンドでスポーンする大きな「キック」エージェントはデルタレゾネーターを「リング」させ、そのバンドに結合した他のエージェントを同期させる。

**入力ソース**：`NeuralRhythms` は `DorsalStream`（§6.2.4）によって駆動され、3バンドフラックス検出を介してオーディオ信号からリズミックエネルギーを抽出する。DorsalStreamはメインスレッドで同期的に実行され、各フレームでオシレーターバンクに `(u_theta, u_delta, vitality)` を供給する。

## 5.3 蔵本同期

`entrain` ArticulationCore は結合振動子の蔵本モデルを使用する。

$$ \frac{d\theta_i}{dt} = \omega_i + \frac{K}{N} \sum_{j=1}^N \sin(\theta_j - \theta_i) $$

Conchordal では、「結合」$K$ は他のすべてのエージェントに直接ではなく、グローバルな `NeuralRhythms` に対するものである（平均場近似）。

*   **感度**：各エージェントは、どのバンド（デルタ、シータなど）を聴くかを決定する感度プロファイルを持つ。
*   **位相ロック**：エージェントは内部アーティキュレーション位相をレゾネーターの位相に合わせて調整する。

これにより創発的な同期が生じる。ランダムな時間にスポーンしたエージェントは、徐々にアタックをデルタまたはシータバンドのビートに合わせ、中央のシーケンサーなしにコヒーレントなリズムパターンを作り出す。

# 6. システムアーキテクチャと実装詳細

Conchordal は、リアルタイムオーディオ（レイテンシ < 10ms）と重い数値解析（NSGT/畳み込み）の厳格な要件を満たすために Rust で実装されている。アーキテクチャは並行的でロックフリーの設計パターンを使用する。

## 6.1 スレッドモデル

アプリケーションは2つの主要なスレッドコンテキストを作成する：

1.  **オーディオスレッド（リアルタイム優先度）**：
    *   `audio/output.rs` の `cpal` によって管理。
    *   **制約**：ブロックしてはならない。Mutexなし、メモリ割り当てなし。
    *   **責務**：`Population` を反復し、すべてのアクティブエージェントで `render_wave` を呼び出し、出力をミキシングし、ハードウェアバッファにプッシュする。ランドスケープの読み取り専用スナップショットから読み取る。

2.  **分析ワーカー（バックグラウンド優先度）**：
    *   `core/analysis_worker.rs` で定義。
    *   **責務**：スペクトル分析（NSGT）、ラフネス（ERB畳み込み）、調和性（Sibling Projection）の統一処理を単一の専用スレッドで実行。
    *   **入力**：`hop_rx: Receiver<(u64, Arc<[f32]>)>` 経由で時間ドメインオーディオホップを受信。
    *   **出力**：`result_tx` 経由で完全な `AnalysisResult = (frame_id, Landscape)` タプルを送信。
    *   **パラメータ更新**：ランタイムパラメータ変更用に `update_rx` 経由で `LandscapeUpdate` メッセージを受信。

**メイン/GUIスレッド**は `egui` ビジュアライザーと `Rhai` スクリプティングエンジンを実行し、ユーザー入力とシナリオ実行を処理する。

### 6.1.1 分析ワーカーアーキテクチャ

分析ワーカー（`core/analysis_worker.rs`）はプロデューサー-コンシューマーパターンを実装する：

```rust
pub fn run(
    mut stream: AnalysisStream,
    hop_rx: Receiver<(u64, Arc<[f32]>)>,
    result_tx: Sender<AnalysisResult>,
    update_rx: Receiver<LandscapeUpdate>,
)
```

**主要な設計原則**：

1. **ホップスキップなし**：ワーカーはバックログをドレインするが、キューされたすべてのホップを順番に処理する。NSGT-RTは時間連続性を仮定した内部リングバッファを維持する；ホップをドロップすると広帯域アーティファクト（「謎のピーク」）が発生する。

2. **順次処理**：各ホップは正規化器が使用するホップごとの `dt` を保持するために順番に処理される：
   ```rust
   for hop in &hops[1..] {
       analysis = stream.process(hop.as_ref());
   }
   ```

3. **ノンブロッキング結果配信**：結果チャネルでのブロックを避けるために `try_send()` を使用。

## 6.2 データフロー

統一された分析パイプラインは、以前のマルチワーカー設計と比較してデータフローを簡素化する：

```
Audio Input
    │
    ▼
┌─────────────────────────────────────────────────────┐
│  分析ワーカースレッド                                │
│  ┌─────────────────────────────────────────────┐   │
│  │ AnalysisStream (core/stream/analysis.rs)    │   │
│  │  ├── RtNsgtKernelLog2 (NSGTスペクトル)       │   │
│  │  ├── SpectralFrontEnd (正規化)               │   │
│  │  ├── RoughnessKernel (ERB畳み込み)           │   │
│  │  └── HarmonicityKernel (Sibling投影)         │   │
│  └─────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────┘
    │
    ▼ (frame_id, Landscape)
メインスレッド
    │
    ▼
Population (エージェントが適応度のためにLandscapeを読み取る)
```

### 6.2.1 AnalysisStream 処理

`AnalysisStream`（`core/stream/analysis.rs`）はホップごとに完全な分析パイプラインを実行する：

1. **NSGTスペクトル**：`nsgt_rt.process_hop(audio)` → パワーエンベロープ
2. **スペクトルフロントエンド**：正規化と主観的強度計算
3. **ラフネス計算**：
   - レベル依存ラフネス強度（total/max/p95モード）
   - レベル不変ラフネス形状（正規化密度）
   - `roughness_ratio_to_state01()` による比率から状態へのマッピング
4. **調和性評価**：`harmonicity_kernel.potential_h_from_log2_spectrum()`
5. **ランドスケープアセンブリ**：すべての指標を単一の `Landscape` スナップショットに統合

### 6.2.2 ランドスケープ出力フィールド

結果の `Landscape` には以下が含まれる：

| フィールド | 説明 |
|-------|-------------|
| `nsgt_power` | 生のNSGTパワーエンベロープ |
| `roughness` | ビンごとのラフネス強度（レベル依存） |
| `roughness01` | 正規化ラフネス（0–1範囲） |
| `roughness_scalar_*` | 集約指標（total, max, p95, raw, norm） |
| `harmonicity` | ビンごとの調和ポテンシャル |
| `consonance01` | 統合協和度指標 |
| `subjective_intensity` | 知覚的ラウドネス密度 |
| `loudness_mass` | 統合ラウドネス |
| `rhythm` | `NeuralRhythms` 状態（theta, delta, beta振動） |

### 6.2.3 ランタイムパラメータ更新

`LandscapeUpdate` 構造体は分析パラメータのランタイム変更を可能にする：

| フィールド | 説明 |
|-------|-------------|
| `mirror` | 調和性ミラーウェイト（0 = 上倍音、1 = 下倍音） |
| `limit` | 調和性パラメータリミット |
| `roughness_k` | ラフネス許容度スケーリング |

更新は各バッチ処理前に `stream.apply_update(upd)` で適用される。

この統一アーキテクチャにより、オーディオスレッドは常に物理の一貫したスナップショットを見ることができ、単一の分析ワーカーは正確なスペクトル分析のための時間連続性を維持する。

### 6.2.4 DorsalStream：リズム抽出

`DorsalStream`（`core/stream/dorsal.rs`）は高速リズム抽出とモーター同期を処理し、低レイテンシ応答のために**メインスレッドで同期的に**実行される。`NeuralRhythms` 変調バンク（§5）を駆動する入力信号を提供する。

**処理パイプライン**：

1. **3バンドクロスオーバーフラックス検出**：
   - 低帯域：< 200 Hz
   - 中帯域：200–3000 Hz
   - 高帯域：> 3000 Hz
   - 帯域間で正のフラックスを合計

2. **非線形神経活性化**：
   ```
   drive = tanh(raw_flux × 500.0)
   u_theta = clamp(drive, 0, 1)
   ```
   高ゲイン + tanh飽和がアンビエントシフトを検出

3. **エンベロープ平滑化**：
   - τ = 0.6s時定数のデルタエンベロープ
   - `u_delta` 変調信号を提供

4. **RhythmEngine更新**：
   - オシレーターバンクに `(u_theta, u_delta, vitality)` を供給
   - 更新された `NeuralRhythms` 状態を返す

**出力**（`DorsalMetrics`）：

| フィールド | 説明 |
|-------|-------------|
| `e_low` | 低帯域エネルギー |
| `e_mid` | 中帯域エネルギー |
| `e_high` | 高帯域エネルギー |
| `flux` | 正のフラックス合計（オンセット強度） |

**Vitalityパラメータ**：リズムセクションの自励振動エネルギーを制御（0–1）。高い値は無音時でもリズムが持続することを可能にする。

## 6.3 コンダクター：Rhai によるスクリプティング

Conductor モジュールは、人間のアーティストとエコシステム間のインターフェースとして機能する。[Rhai](https://rhai.rs/) スクリプティング言語を埋め込み、シミュレーション制御のための高レベルAPIを公開する。

### 6.3.1 コアコンセプト

スクリプティングAPIは3つの基本型を中心に構築されている：

| 型 | 説明 |
|------|-------------|
| `SpeciesHandle` | エージェント設定のブループリント/テンプレート |
| `GroupHandle` | スポーンされたエージェントのライブグループへの参照 |
| `SpawnStrategy` | スポーン周波数を決定するアルゴリズム |

### 6.3.2 種とプリセット

**組み込みプリセット**（グローバル変数として利用可能）：

| プリセット | Body Method | 音色 |
|--------|-------------|--------|
| `sine` | Sine | 純音 |
| `harmonic` | Harmonic | デフォルト音色 |
| `saw` | Harmonic | brightness=0.85, width=0.2 |
| `square` | Harmonic | brightness=0.65, width=0.1 |
| `noise` | Harmonic | brightness=1.0, motion=1.0, width=0.35 |

**種ビルダー**（`SpeciesHandle` のチェイン可能メソッド）：

| メソッド | 説明 |
|--------|-------------|
| `derive(species)` | 修正用に種をクローン |
| `.amp(value)` | 振幅を設定（0–1） |
| `.freq(value)` | 周波数を設定（Hz）；`PitchMode::Lock` を設定 |
| `.timbre(brightness, width)` | 音色パラメータを設定 |
| `.brain(name)` | アーティキュレーションタイプを設定：`"drone"`, `"seq"`, `"entrain"` |
| `.phonation(name)` | 発声タイプを設定：`"hold"`, `"decay"`, `"grain"` |
| `.metabolism(rate)` | エネルギー消費率を設定 |
| `.adsr(a, d, s, r)` | エンベロープパラメータを設定 |

### 6.3.3 グループライフサイクル

**グループ作成**：
```rhai
let g = create(species, count);  // GroupHandle を返す（Draft状態）
```

**グループ状態マシン**：

```
   create()          flush()/wait()         release()/scope exit
Draft ────────────────► Live ──────────────────► Released
  │                                                 │
  │ (flush なしでスコープ終了)                        │
  ▼                                                 ▼
Dropped ◄───────────────────────────────────────────
```

| 状態 | 説明 |
|-------|-------------|
| `Draft` | 作成されたがスポーンされていない；すべてのパラメータを変更可能 |
| `Live` | スポーンされてアクティブ；可変パラメータのみ変更可能（amp, freq, timbre） |
| `Released` | フェードアウトで削除マーク |
| `Dropped` | スポーンされなかった（警告を生成） |

**グループビルダー**（`GroupHandle` のチェイン可能メソッド）：

| メソッド | Draft | Live | 説明 |
|--------|-------|------|-------------|
| `.amp(value)` | ✓ | ✓ | 振幅を設定/更新 |
| `.freq(value)` | ✓ | ✓ | 周波数を設定/更新（Draftの場合strategyをクリア） |
| `.timbre(b, w)` | ✓ | ✓ | 音色を設定/更新 |
| `.place(strategy)` | ✓ | ✗ | スポーン周波数strategyを設定 |
| `.brain(name)` | ✓ | ✗ | アーティキュレーションタイプを設定 |
| `.phonation(name)` | ✓ | ✗ | 発声タイプを設定 |
| `.metabolism(rate)` | ✓ | ✗ | 代謝率を設定 |
| `.adsr(a, d, s, r)` | ✓ | ✗ | エンベロープを設定 |

### 6.3.4 スポーン戦略

戦略は複数のエージェントをスポーンする際の周波数割り当て方法を決定する：

| 戦略 | コンストラクタ | 説明 |
|----------|-------------|-------------|
| Consonance | `consonance(root_freq)` | root倍率範囲内で最高協和度の位置を選択 |
| Consonance Density | `consonance_density(min, max)` | 周波数範囲内で協和度に基づく重み付けランダム |
| Random Log | `random_log(min, max)` | 対数周波数の一様分布 |
| Linear | `linear(start, end)` | エージェント間の線形補間 |

**Consonance戦略修飾子**：
- `.range(min_mul, max_mul)`：倍率範囲を設定（デフォルト：1–4）; spawn freq = root × [min_mul, max_mul]
- `.min_dist(erb)`：ERB単位の最小間隔を設定（デフォルト：1.0）

### 6.3.5 タイムライン制御

| 関数 | 説明 |
|----------|-------------|
| `create(species, count)` | `species`から`count`個のエージェントの新規グループを作成；Draft状態の`GroupHandle`を返す |
| `wait(sec)` | ドラフトをコミットし、カーソルを `sec` 秒進める |
| `flush()` | 時間を進めずにドラフトをコミット |
| `release(group)` | フェードでグループを削除マーク |

### 6.3.6 スコープとシーン

**シーン**：自動クリーンアップを持つ名前付きセクション：
```rhai
scene("intro", || {
    let g = create(sine, 3);
    flush();
    wait(2.0);
});  // g はここで自動的にリリース
```

**Play**：シーンマーカーなしのスコープ実行：
```rhai
play(|| {
    let g = create(sine, 1);
    flush();
    wait(1.0);
});
```

**Parallel**：複数のクロージャを同時実行：
```rhai
parallel([
    || { create(sine, 1); wait(0.5); },
    || { create(sine, 1); wait(1.0); }
]);  // カーソルは最大終了時間（1.0）に進む
```

### 6.3.7 ワールドパラメータ

| 関数 | 説明 |
|----------|-------------|
| `seed(value)` | 再現性のためのランダムシードを設定 |
| `set_harmonicity_mirror_weight(value)` | 上倍音/下倍音バランスを調整（0–1） |
| `set_global_coupling(value)` | グローバル社会的結合強度を設定 |
| `set_roughness_k(value)` | ラフネス許容度パラメータを設定 |

### 6.3.8 サンプルスクリプト

```rhai
seed(12345);

// 種を定義
let anchor = derive(sine).amp(0.4).phonation("hold");
let voice = derive(harmonic).amp(0.2).timbre(0.7, 0.1);

scene("exposition", || {
    // アンカードローンを作成
    let a = create(anchor, 1).freq(220.0);
    flush();
    wait(1.0);

    // 倍音列上にボイスをスポーン
    let strat = consonance(220.0).range(1.0, 4.0).min_dist(0.8);
    for i in 0..4 {
        create(voice, 1).place(strat);
        wait(0.5);
    }

    // 物理を変調
    set_harmonicity_mirror_weight(0.5);
    wait(2.0);
});
```

**シナリオ解析**：シナリオは `ScriptHost::load_script()` を介して `.rhai` ファイルから読み込まれる。この分離により、ユーザーは「マクロ構造」（物語的弧、変化する物理法則）を作曲し、「ミクロ構造」（特定の音とリズム）はエージェントがそれらの変化に適応することから創発する。

# 7. ケーススタディ：創発的挙動の分析

以下の例は `samples/` ディレクトリから派生しており、特定のパラメータ構成が現在のスクリプティングAPIを使用してどのように複雑な音楽的挙動につながるかを示す。

## 7.1 ケーススタディ：ポリリズム的相互作用（`samples/02_mechanisms/rhythmic_sync.rhai`）

このスクリプトは並列タイムラインを通じたポリリズムの創発を示す。

```rhai
let click = derive(sine)
    .amp(0.4)
    .phonation("decay")
    .adsr(0.01, 0.1, 0.0, 0.2);

parallel([
    || {
        for i in 0..8 {
            create(click, 1).freq(60.0);
            wait(0.5);
        }
    },
    || {
        for i in 0..6 {
            create(click, 1).freq(120.0);
            wait(0.666);
        }
    }
]);
```

**分析**：
1. **種定義**：`click` 種は `sine` から派生し、decay発声と短いADSRエンベロープを持つ。
2. **並列実行**：2つの独立したタイムラインが同時に実行される—1つは60 Hzで0.5秒間隔（4:4）、もう1つは120 Hzで0.666秒間隔（3:3）。
3. **創発**：4対3のポリリズムは明示的な同期なしに12ビートサイクルを作り出す。`parallel()` 関数はカーソルを最大の子終了時間に進める。

## 7.2 ケーススタディ：鏡像双対性（`samples/04_ecosystems/mirror_dualism.rhai`）

このスクリプトは `mirror_weight` パラメータの構造的役割を探求する。

```rhai
let anchor = derive(sine).amp(0.4).phonation("hold");
let voice = derive(sine).amp(0.2).phonation("hold");

scene("Mirror Dualism", || {
    create(anchor, 1).freq(261.63);
    flush();
    wait(0.8);

    set_harmonicity_mirror_weight(0.0);
    for i in 0..4 {
        let strat = consonance(261.63).range(1.0, 3.0).min_dist(0.9);
        create(voice, 1).place(strat);
    }
    wait(1.5);

    set_harmonicity_mirror_weight(1.0);
    for i in 0..4 {
        let strat = consonance(261.63).range(0.8, 2.5).min_dist(0.9);
        create(voice, 1).place(strat);
    }
    wait(1.5);
});
```

**分析**：
1. **セットアップ**：C4（261.63 Hz）のアンカードローンで `phonation("hold")` により持続音。
2. **状態A（上倍音/長調）**：`set_harmonicity_mirror_weight(0.0)`。ボイスは `consonance()` 戦略を使用して倍音列上にスポーン。システムは上倍音関係を好む—エージェントはE4とG4周辺にクラスタリングし、ハ長調三和音を形成。
3. **状態B（下倍音/短調）**：`set_harmonicity_mirror_weight(1.0)`。ランドスケープが下倍音投影に反転。エージェントは異なる音程で安定性を見つけ、フリギア/短調のテクスチャを作り出す。
4. **スコープクリーンアップ**：`scene()` は終了時にすべてのグループを自動的にリリース。

## 7.3 ケーススタディ：ドリフトとフロー（`samples/04_ecosystems/drift_flow.rhai`）

このスクリプトはライブパラメータ更新と周波数ドリフトを検証する。

```rhai
let anchor = derive(sine).amp(0.6).phonation("hold");
let slider = derive(sine).amp(0.4).phonation("hold");
let swarm = derive(sine).amp(0.15).phonation("hold");

scene("Drift Flow", || {
    let a = create(anchor, 1).freq(65.41);
    let s = create(slider, 1).freq(138.59);
    flush();
    wait(1.0);

    s.freq(220.0);
    flush();
    wait(1.5);

    release(s);
    wait(0.5);

    for i in 0..5 {
        let strat = consonance(130.0).range(1.0, 4.0).min_dist(1.0);
        create(swarm, 1).place(strat);
        wait(0.6);
    }

    a.freq(87.31);
    flush();
    wait(1.0);
});
```

**分析**：
1. **初期状態**：アンカーがC2（65.41 Hz）、スライダーがC#3（138.59 Hz）—不協和な短9度。
2. **ライブ更新**：`s.freq(220.0)` はランタイム周波数変更を示す。スライダーはA3にスムーズに遷移し、アンカーとの協和関係を作る。
3. **リリース**：`release(s)` はスライダーをフェードアウト削除にマーク。
4. **スワームスポーン**：5つのエージェントが130 Hzの倍音列上に最小1.0 ERB間隔で順次スポーン。
5. **アンカー移動**：`a.freq(87.31)` はアンカーをF2にシフト。「アンカー」エージェントでも動的に再配置でき、スワームが新しいルート周辺で再組織化することを示す。

# 8. 結論

Conchordal は、生物模倣型計算オーディオの概念実証を成功裏に確立した。音楽理論の硬直した抽象化（音符、グリッド、BPM）を連続的な生理学的モデル（`Log2Space`、ERB帯域、神経振動）で置き換えることで、音楽が構築されるのではなく成長するシステムを創造した。

技術アーキテクチャ—`Log2Space` 座標系と「Sibling Projection」アルゴリズムを基盤とする—は、この新しいパラダイムの堅牢な数学的基盤を提供する。Rustの使用により、これらの複雑な生物学的シミュレーションがリアルタイムで実行でき、ALife研究とパフォーマティブな楽器の間のギャップを埋める。

Conchordal の将来の開発は、空間化（ランドスケープの3D空間への拡張）と進化遺伝学（成功したエージェントが `TimbreGenotype` を継承できるようにする）に焦点を当て、音と生命のアナロジーをさらに深める。

# 付録A：主要システムパラメータ

## A.1 コア分析パラメータ

| パラメータ | モジュール | 単位 | 説明 |
| :--- | :--- | :--- | :--- |
| `bins_per_oct` | `Log2Space` | Int | 周波数グリッドの解像度（典型的に48-96）。 |
| `sigma_cents` | `Harmonicity` | Cents | 倍音ピークの幅。低い = 厳格なイントネーション。 |
| `mirror_weight` | `Harmonicity` | 0.0-1.0 | 上倍音（長調）と下倍音（短調）重力のバランス。 |
| `roughness_k` | `Roughness` | Float | ラフネスマッピングの飽和パラメータ。デフォルト：$\approx 0.4286$。 |
| `roughness_weight` | `Landscape` | Float | 協和度計算におけるラフネスペナルティの重み。デフォルト：1.0。 |
| `vitality` | `DorsalStream` | 0.0-1.0 | リズムセクションの自励振動エネルギー。 |

## A.2 AgentControl パラメータ

`AgentControl` 階層はエージェントの主要な設定インターフェースを提供する。

### A.2.1 BodyControl

| パラメータ | デフォルト | 範囲 | 説明 |
| :--- | :--- | :--- | :--- |
| `method` | `Sine` | — | `Sine` または `Harmonic`（スポーン後不変） |
| `amp` | 0.18 | 0–1 | 出力振幅 |

**TimbreControl**（`BodyControl` にネスト）：

| パラメータ | デフォルト | 範囲 | 説明 |
| :--- | :--- | :--- | :--- |
| `brightness` | 0.6 | 0–1 | スペクトル傾斜（高い = 明るい） |
| `inharmonic` | 0.0 | 0–1 | 非調和性係数（スティフネス） |
| `width` | 0.0 | 0–1 | ユニゾン/コーラスデチューン量 |
| `motion` | 0.0 | 0–1 | ジッター/ビブラート深度 |

### A.2.2 PitchControl

| パラメータ | デフォルト | 範囲 | 説明 |
| :--- | :--- | :--- | :--- |
| `mode` | `Free` | — | `Free`（自律）または `Lock`（固定周波数） |
| `freq` | 220.0 | 1–20000 Hz | 中心周波数（Free）またはロック周波数（Lock） |
| `range_oct` | 6.0 | 0–6 | オクターブ単位の最大探索範囲 |
| `gravity` | 0.5 | 0–1 | 音域重力強度 |
| `exploration` | 0.0 | 0–1 | ランダム探索確率 |
| `persistence` | 0.5 | 0–1 | 満足時の移動抵抗 |

### A.2.3 PhonationControl

| パラメータ | デフォルト | 範囲 | 説明 |
| :--- | :--- | :--- | :--- |
| `type` | `Interval` | — | `Interval`、`Clock`、`Field`、`Hold`、または `None` |
| `density` | 0.5 | 0–1 | ノートオンセット密度/レート |
| `sync` | 0.5 | 0–1 | シータリズムへの同期 |
| `legato` | 0.5 | 0–1 | ノートデュレーション（0 = スタッカート、1 = レガート） |
| `sociality` | 0.0 | 0–1 | 社会的結合強度 |

### A.2.4 PerceptualControl

| パラメータ | デフォルト | 範囲 | 説明 |
| :--- | :--- | :--- | :--- |
| `enabled` | true | — | 知覚適応の有効化/無効化 |
| `adaptation` | 0.5 | 0–1 | 時定数（0 = 速い適応、1 = 遅い） |
| `novelty_bias` | 1.0 | 0–∞ | 飽きペナルティの重み |
| `self_focus` | 0.15 | 0–1 | 自己注入比 |

## A.3 音色パラメータ（TimbreGenotype）

`HarmonicBody` が使用する内部音色表現：

| パラメータ | デフォルト | 説明 |
| :--- | :--- | :--- |
| `mode` | `Harmonic` | `Harmonic`（整数倍）または `Metallic`（非整数）。 |
| `stiffness` | 0.0 | 非調和性係数（`timbre.inharmonic` からマップ）。 |
| `brightness` | 0.6 | スペクトル傾斜（`timbre.brightness` からマップ）。 |
| `comb` | 0.0 | 偶数倍音減衰。 |
| `damping` | 0.5 | エネルギー依存高周波減衰。 |
| `vibrato_rate` | 5.0 Hz | ビブラートLFO周波数。 |
| `vibrato_depth` | 0.0 | ビブラート範囲（`timbre.motion * 0.02` からマップ）。 |
| `jitter` | 0.0 | ピンクノイズFM強度（`timbre.motion` からマップ）。 |
| `unison` | 0.0 | コーラス効果用デチューン量（`timbre.width` からマップ）。 |

## A.4 スクリプティングAPIクイックリファレンス

### A.4.1 種プリセット

| プリセット | Body | Brightness | Width | Motion |
| :--- | :--- | :--- | :--- | :--- |
| `sine` | Sine | — | — | — |
| `harmonic` | Harmonic | 0.6 | 0.0 | 0.0 |
| `saw` | Harmonic | 0.85 | 0.2 | 0.0 |
| `square` | Harmonic | 0.65 | 0.1 | 0.0 |
| `noise` | Harmonic | 1.0 | 0.35 | 1.0 |

### A.4.2 ブレインタイプ（アーティキュレーション）

| スクリプト名 | コア | 説明 |
| :--- | :--- | :--- |
| `"entrain"` | `KuramotoCore` | 蔵本スタイルの神経リズム結合 |
| `"seq"` | `SequencedCore` | 固定時間エンベロープ |
| `"drone"` | `DroneCore` | ゆっくりしたスウェイを持つ連続トーン |

### A.4.3 発声タイプ

| スクリプト名 | タイプ | 説明 |
| :--- | :--- | :--- |
| `"hold"` | `Hold` | ライフサイクルごとに一度持続 |
| `"decay"` | `Interval` | 減衰を伴う確率的オンセット |
| `"grain"` | `Field` | グラニュラー、フィールド応答 |

### A.4.4 ワールドパラメータ関数

| 関数 | パラメータ | 説明 |
| :--- | :--- | :--- |
| `seed(value)` | — | ランダムシードを設定 |
| `set_harmonicity_mirror_weight(v)` | `mirror` | 上倍音/下倍音バランス（0–1） |
| `set_global_coupling(v)` | `coupling` | グローバル社会的結合強度 |
| `set_roughness_k(v)` | `roughness_k` | ラフネス許容度

# 付録B：数学的要約

**協和度適応度関数：**

$$ C_{signed} = \text{clip}(H_{01} - w_r \cdot R_{01},\; -1,\; 1) $$

$$ C_{01} = \frac{C_{signed} + 1}{2} $$

**ラフネス飽和マッピング**（参照正規化比 $x$ から $R_{01} \in [0,1]$ へ）：

$$
R_{01}(x; k) = \begin{cases}
0 & \text{if } x \leq 0 \\
x \cdot \frac{1}{1+k} & \text{if } 0 < x < 1 \\
1 - \frac{k}{x+k} & \text{if } x \geq 1
\end{cases}
$$

ここで $k$ は `roughness_k`（デフォルト $\approx 0.4286$）。関数は $x=1$ で連続であり、$x \to \infty$ で1に飽和する。

**調和性投影（Siblingアルゴリズム）：**
$$ H[i] = (1-\alpha)\sum_m \left( \sum_k A[i+\log_2(k)] \right)[i-\log_2(m)] + \alpha \sum_m \left( \sum_k A[i-\log_2(k)] \right)[i+\log_2(m)] $$

**ラフネス畳み込み：**
$$ R_{shape}(z) = \int A(\tau) \cdot K_{plomp}(|z-\tau|_{ERB}) d\tau $$